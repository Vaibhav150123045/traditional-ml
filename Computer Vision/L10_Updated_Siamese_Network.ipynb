{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s2CdjomabH66"
      },
      "outputs": [],
      "source": [
        "# Visualizing 1 Forgery Signature pair\n",
        "forgery_results = []\n",
        "img1 = preprocess_image(path+forgery_imgs[0][1])\n",
        "img2 = preprocess_image(path+forgery_imgs[0][2])\n",
        "embed1 = signature_embeddings.predict(np.expand_dims(img1,axis=0))\n",
        "embed2 = signature_embeddings.predict(np.expand_dims(img2,axis=0))\n",
        "forgery_results.append(embed1)\n",
        "forgery_results.append(embed2)"
      ],
      "id": "s2CdjomabH66"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wI525M8MbWSR"
      },
      "outputs": [],
      "source": [
        "forgery_results = np.array(forgery_results)"
      ],
      "id": "wI525M8MbWSR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lPzJzmdYbZf4"
      },
      "outputs": [],
      "source": [
        "forgery_results.shape"
      ],
      "id": "lPzJzmdYbZf4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gpg5ylzTbevR"
      },
      "outputs": [],
      "source": [
        "# Save embeddings for visualization in projector\n",
        "np.savetxt(\"vecs_forgery.tsv\", forgery_results.reshape((2,-1)), delimiter='\\t')"
      ],
      "id": "Gpg5ylzTbevR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7dtqaD5czCy"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?id=119ggTHKoBIB6rTq3c0_qMQcnpkbPF48_\" width=600>"
      ],
      "id": "V7dtqaD5czCy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGBAWh6DevPA"
      },
      "source": [
        "Similar signatures have less euclidean distance, while the different signatures have comparatively higher euclidean distance"
      ],
      "id": "JGBAWh6DevPA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUXUrvlpaMSf"
      },
      "source": [
        "Now lets split the data into two sets\n",
        "\n",
        "- to compute the threshold and accuracy in the first set of data\n",
        "- Use the same threshold to find the accuracy in the test set"
      ],
      "id": "BUXUrvlpaMSf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLrHJfQx0ZYS"
      },
      "outputs": [],
      "source": [
        "labels = pairs_new.iloc[:,3].values\n",
        "dist = pairs_new['distance'].values"
      ],
      "id": "RLrHJfQx0ZYS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAtyEgtbZxX3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dist_train,dist_test,labels_train,labels_test = train_test_split(dist,labels,test_size=0.2,random_state=42)"
      ],
      "id": "BAtyEgtbZxX3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvAnkehF1UCm"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy_thresh(predictions, labels):\n",
        "\n",
        "    dmax = np.max(predictions)\n",
        "    dmin = np.min(predictions)\n",
        "    nsame = np.sum(labels == 1)\n",
        "    ndiff = np.sum(labels == 0)\n",
        "\n",
        "    step = 0.01\n",
        "    max_acc = 0\n",
        "    best_thresh = -1\n",
        "    best_labels = None\n",
        "\n",
        "    for d in np.arange(dmin, dmax+step, step):\n",
        "\n",
        "        best_labels = (predictions <= d).astype(int)\n",
        "\n",
        "    # Calculate tp, tn, fp, fn using best_labels and ground truth labels\n",
        "        tp = np.sum((best_labels == 1) & (labels == 1))\n",
        "        tn = np.sum((best_labels == 0) & (labels == 0))\n",
        "        fp = np.sum((best_labels == 1) & (labels == 0))\n",
        "        fn = np.sum((best_labels == 0) & (labels == 1))\n",
        "        accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "        if accuracy>max_acc:\n",
        "          max_acc = accuracy\n",
        "          best_thresh = d\n",
        "\n",
        "    return max_acc, best_thresh"
      ],
      "id": "LvAnkehF1UCm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWWpJr3t1h9K"
      },
      "outputs": [],
      "source": [
        "acc,thresh = compute_accuracy_thresh(dist_train,labels_train)"
      ],
      "id": "IWWpJr3t1h9K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVLveCB71qMi"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "acc"
      ],
      "id": "DVLveCB71qMi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jaz35lvc1ssB"
      },
      "outputs": [],
      "source": [
        "# Threshold\n",
        "thresh"
      ],
      "id": "Jaz35lvc1ssB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUgXFTTzazB3"
      },
      "source": [
        "Now lets use the same threshold to find the accuracy of the test set"
      ],
      "id": "dUgXFTTzazB3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcTA0zQ3a3UG"
      },
      "outputs": [],
      "source": [
        "# Computing Test Accuracy with the train threshold\n",
        "def compute_accuracy_thresh_test(predictions, labels,d):\n",
        "\n",
        "    best_labels = (predictions <= d).astype(int)\n",
        "    tp = np.sum((best_labels == 1) & (labels == 1))\n",
        "    tn = np.sum((best_labels == 0) & (labels == 0))\n",
        "    fp = np.sum((best_labels == 1) & (labels == 0))\n",
        "    fn = np.sum((best_labels == 0) & (labels == 1))\n",
        "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "\n",
        "    return accuracy"
      ],
      "id": "UcTA0zQ3a3UG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_luCm-aCa90V"
      },
      "outputs": [],
      "source": [
        "# Test Accuracy\n",
        "test_acc= compute_accuracy_thresh_test(np.array(dist_test), np.array(labels_test),thresh)\n",
        "test_acc"
      ],
      "id": "_luCm-aCa90V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXaDTxcEQe9K"
      },
      "outputs": [],
      "source": [
        "# Train loss vs validation loss\n",
        "plt.plot(history.history['loss'],label='Train Loss')\n",
        "plt.plot(history.history['val_loss'],label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "GXaDTxcEQe9K"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7suZ7JMrcxTP"
      },
      "source": [
        "### Contrastive Loss Vs Triplet Loss\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Loss</th>\n",
        "    <th>Train Accuracy</th>\n",
        "    <th>Test Accuracy</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Contrastive Loss</td>\n",
        "    <td>92.56</td>\n",
        "    <td>63.81</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Triplet Loss</td>\n",
        "    <td>82.66</td>\n",
        "    <td>82.48</td>\n",
        "  </tr>\n",
        "</table>"
      ],
      "id": "7suZ7JMrcxTP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU-YW_UAd2Cu"
      },
      "source": [
        "> **Note:** Due to insufficent memory and GPu in colab, the model with triplet loss has been trained only using 20,000 triplets out of 44,000 triplets. The performance of the model can be improved by training with more samples."
      ],
      "id": "gU-YW_UAd2Cu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf_iZRNkcZhv"
      },
      "source": [
        "## Summary"
      ],
      "id": "Qf_iZRNkcZhv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWec-Tm8cF2Y"
      },
      "source": [
        "- A **Siamese neural network** is an artificial neural network that contains two or more identical subnetwork which is also known as twin neural network or sister network.\n",
        "\n",
        "- Siamese network takes two different inputs passed through two similar subnetworks with the same architecture, parameters, and weights.\n",
        "\n",
        "- Siamese networkâ€™s objective is to classify if the two inputs are the same or different using the Similarity score.\n",
        "\n",
        "- The Similarity score can be calculated using **Contrastive function**, or **Triplet loss**, which are techniques for the general distance metric learning approach.\n",
        "\n",
        "- Since training of Siamese networks involves pairwise learning usual, Cross entropy loss cannot be used in this case, mainly two loss functions are used, they are\n",
        " - **Contrastive loss**\n",
        " - **Triplet loss**\n",
        "\n",
        "- **Contrastive loss** is a metric learning objective function where we learn from training data examples structured as pairs:\n",
        " - Positive pairs (examples that belong to the same class)\n",
        " - Negative pairs (examples that belong to different classes).\n",
        "\n",
        "- The contrastive loss function is set up such that we minimize the distance between embeddings for positive pairs, and maximize the distance between embeddings for negative pairs.\n",
        "\n",
        "- The **triplet loss** function is an alternative to the contrastive loss function. It has convergence advantages over contrastive loss function\n",
        "\n",
        "- The distance between the baseline input and the positive input is reduced to a minimum, while the distance between the baseline input and the negative input is increased.\n",
        "\n",
        "- The triplet loss function aims to learn a distance between representations such that the anchor-to-positive distance is less than the anchor-to-negative distance."
      ],
      "id": "vWec-Tm8cF2Y"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 783.94029,
      "end_time": "2022-08-05T10:26:42.484117",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-08-05T10:13:38.543827",
      "version": "2.3.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}